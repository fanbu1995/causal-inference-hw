---
title: "STA640 Homework 2"
author: "Fan Bu"
date: "9/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem 1
```{r, message=FALSE, warning=FALSE}
library(tableone)
library(survey)
library(reshape2)
library(ggplot2)
library(tidyverse)
data = read_delim('HW2_data.txt', delim=' ',
                  col_types = 'fnffffffnnnf')
```

### (a)
Estimate propensity score with logistic regression using all covariates as main effects (note that I've tried adding higher-order terms, but it tends to hinder algorithm convergence and doesn't improve balance by much). Then obtain the inverse probability weights.
```{r, message=FALSE}
# centering the continuous variables helps...
data[,c('i_age','com_t','pcs_sd','mcs_sd')] = scale(data[,c('i_age','com_t','pcs_sd','mcs_sd')],scale=FALSE)

ps.model = glm(pg ~ i_age + i_sex + i_race + i_educ + 
                 i_insu + i_drug + i_seve + com_t + 
                 pcs_sd + mcs_sd, 
               data=data, family=binomial('logit'))
```

```{r, echo=FALSE}
ps.model = readRDS('ps_model.rds')
```

```{r}
ps = ps.model$fitted.values %>% as.numeric()

data$ipw = 1
data$ipw[data$pg == 2] = 1/ps[data$pg == 2]
data$ipw[data$pg == 1] = 1/(1-ps[data$pg == 1])

data$ow = 1
data$ow[data$pg == 2] = 1 - ps[data$pg == 2]
data$ow[data$pg == 1] = ps[data$pg == 1]
```

Examine covariate balance. Here we have achieved good balance (ASD < 0.1) for some of the covariates, but for the others, there is still imbalance.

Note that there does exist a couple of subjects (subject 5 and 130) with extremely low ($<0.001$) or extremely high ($>0.999$) estimated propensity scores. And here I will exclude those extreme subjects. 
```{r}
## Weighted data
dataIPW <- svydesign(ids = ~ 1, 
                     data = data[ps > 0.001 & ps < 0.999,], 
                     weights = ~ ipw)

vars = names(data)[2:11]

## Construct a table that checks balance
tabWeighted <- svyCreateTableOne(vars = vars, strata = 'pg',
                                 data = dataIPW, test = FALSE)
## Show table with SMD
print(tabWeighted, smd = TRUE)
```


### (b)

Below is the histogram of estimated propensity scores by group.

```{r, echo=FALSE}
data$ps = ps

ggplot(data, aes(x=ps, fill=pg)) +
  geom_histogram(bins=30, position='dodge') +
  labs(fill='physician\ngroup', x='propensity score')
```

And also the Love plot showing ASD before and after matching.

```{r, echo=FALSE}
# nothing
tabUnmatched <- CreateTableOne(vars = vars, strata = "pg", data = data, test = FALSE)

## Weighted data (OW)
dataOW <- svydesign(ids = ~ 1, data = data, weights = ~ ow)

## Construct a table that checks balance
tabWeightedOW <- svyCreateTableOne(vars = vars, strata = 'pg',
                                 data = dataOW, test = FALSE)

```


```{r, echo=FALSE}
## Construct a data frame containing variable name and SMD from all methods
dataPlot <- data.frame(variable  = rownames(ExtractSmd(tabUnmatched)),
                       Unweighted = as.numeric(ExtractSmd(tabUnmatched)),
                       IPW  = as.numeric(ExtractSmd(tabWeighted)),
                       OW = as.numeric(ExtractSmd(tabWeightedOW)))

## Create long-format data for ggplot2
dataPlotMelt <- melt(data          = dataPlot,
                     id.vars       = c("variable"),
                     variable.name = "Method",
                     value.name    = "SMD")

## Order variable names by magnitude of SMD
varNames <- as.character(dataPlot$variable)[order(dataPlot$Unweighted)]

## Order factor levels in the same order
dataPlotMelt$variable <- factor(dataPlotMelt$variable,
                                levels = varNames)

## Plot using ggplot2
ggplot(data = dataPlotMelt,
       mapping = aes(x = variable, y = SMD, group = Method, color = Method)) +
    #geom_line() +
    geom_hline(yintercept = 0.1, color = "black", size = 0.3) +
    geom_point() +
    coord_flip() +
    theme_bw() + theme(legend.key = element_blank())
```


We can see that the original data (before weighting) do not have good balance on most of the covariates, in particular `race` and `comorbidity`, but there is some overlap between the two groups. After weighting, we achieve better balance in the covariates. 

### (c)

(The table generated in R Markdown is a bit ugly.. Sorry about that.)

```{r get weighted average function, echo=FALSE}
weight_avg <- function(x, w, varname=NULL){
  if(is.numeric(x)){
    # continuous variable
    res = sum(w*x)/sum(w)
    names(res) = varname
    res
  }else{
    res = NULL
    names = NULL
    for(l in levels(x)){
      freq.l = sum((x==l) * w)/sum(w)
      res = c(res, freq.l)
      names = c(names, paste0(varname,'=',l))
    }
    names(res) = names
    res
  }
}

get_var_wa <- function(dat, varname){
  res = NULL
  
  x = dat[,varname,drop=TRUE]
  n = nrow(dat)
  
  # unweighted
  uni_W = rep(1,n)
  res = cbind(res, weight_avg(x[dat$pg==1], uni_W[dat$pg==1], varname))
  res = cbind(res, weight_avg(x[dat$pg==2], uni_W[dat$pg==2], varname))
  res = cbind(res, weight_avg(x, uni_W, varname))
  
  # IPW
  res = cbind(res, weight_avg(x, dat$ipw, varname))
  
  # OW
  res = cbind(res, weight_avg(x, dat$ow, varname))
  
  res
}

```


```{r construct the weighted average table, echo=FALSE}
tab = NULL

data_orig = read_delim('HW2_data.txt', delim=' ',
                  col_types = 'fnffffffnnnf')

# get original continuous columns
data_orig$ipw = data$ipw
data_orig$ow = data$ow
data_orig$ps = data$ps

for(v in vars){
  tab = rbind(tab, get_var_wa(data_orig, v))
}

tab = as.data.frame(tab)
names(tab) = c('PG 1 (unadj.)', 'PG 2 (unadj.)', 
               'Overall (unadj.)', 'IPW (adjusted)', 
               'OW (adjusted)')
knitr::kable(tab,digits=3)
```


<!-- |     |     |Unadjusted |       |    Adjusted |   | -->
<!-- |-----|------|-------|-------|-------|----------| -->
<!-- |     | **PG 1** | **PG 2** | **Overall** |  **IPW** |  **OW**  | -->
<!-- | Age (yrs) |  40.45 | 39.65 |        |  -->

## (d)

The table below summarizes ATE and ATO estimates (with un-normalized and normalized weights). Here the standard errors are calculated via bootstrap.

ATE and ATO are different because they focus on different target populations. The former focuses on the entire (sample) population while the latter has much more emphasis on the overlapping portion of the sample population. 

Within each weighting scheme, we can see that when using normalized weights, the standard errors tend to be relatively lower.

```{r, echo=FALSE}
get_weighted_tau <- function(y, z, w, normalize=TRUE){
  if(normalize){
    tau = sum((y[z==1]==1) * w[z==1])/ sum(w[z==1]) - 
      sum((y[z==2]==1) * w[z==2])/ sum(w[z==2])
  }else{
    n = length(y)
    tau = (sum((y[z==1]==1) * w[z==1]) - sum((y[z==2]==1) * w[z==2]))/n
  }
  tau
}

get_sd <- function(y,z,w,B=5000,normalize=TRUE){
  n = length(y)
  boot = sapply(1:B, function(i) {
    samp = sample(n,replace = TRUE)
    get_weighted_tau(y[samp],z[samp],w[samp],normalize)
  })
  #print(boot)
  sd(boot)
}

```


```{r,echo=FALSE,eval=FALSE}
ATE = NULL
ATE = c(ATE, get_weighted_tau(data$i_aqoc, data$pg, data$ipw, normalize = FALSE))
ATE = c(ATE, get_sd(data$i_aqoc, data$pg, data$ipw, normalize = FALSE))
ATE = c(ATE, get_weighted_tau(data$i_aqoc, data$pg, data$ipw, normalize = TRUE))
ATE = c(ATE, get_sd(data$i_aqoc, data$pg, data$ipw, normalize = TRUE))

ATO = NULL
ATO = c(ATO, get_weighted_tau(data$i_aqoc, data$pg, data$ow, normalize = FALSE))
ATO = c(ATO, get_sd(data$i_aqoc, data$pg, data$ow, normalize = FALSE))
ATO = c(ATO, get_weighted_tau(data$i_aqoc, data$pg, data$ow, normalize = TRUE))
ATO = c(ATO, get_sd(data$i_aqoc, data$pg, data$ow, normalize = TRUE))

res = rbind(ATE, ATO)
res = as.data.frame(res)
names(res) = c('est. (un-normalized)', 'sd (un-normalized)',
               'est. (normalized)', 'sd (normalized)')
```

```{r,echo=FALSE}
res = readRDS('ATE_ATO_res.rds')
knitr::kable(res,digits = 3)
```

## Problem 2

### (a) 

Estimate PS with `sex` included, and then do IPW.
```{r}
ps.model = glm(pg ~ i_age + i_sex + i_race + i_educ + 
                 i_insu + i_drug + i_seve + com_t + 
                 pcs_sd + mcs_sd, 
               data=data, family=binomial('logit'))
data$ps = ps.model$fitted.values %>% as.numeric()

data$ipw = 1
data$ipw[data$pg == 2] = 1/ps[data$pg == 2]
data$ipw[data$pg == 1] = 1/(1-ps[data$pg == 1])
```

The ATE estimate (and standard error) is
```{r}
data_sex = data %>% filter(i_sex==1)
ATE1 = get_weighted_tau(data_sex$i_aqoc, data_sex$pg, 
                        data_sex$ipw, normalize = TRUE)
SD1 = get_sd(data_sex$i_aqoc, data_sex$pg, 
             data_sex$ipw, normalize = TRUE)
cat(round(ATE1,4), paste0('(',round(SD1,4),')'),'\n')
```

### (b)
Estimate PS without `sex` as a variable in the logistic regression model, and then do IPW.
```{r}
ps.model = glm(pg ~ i_age + i_race + i_educ + 
                 i_insu + i_drug + i_seve + com_t + 
                 pcs_sd + mcs_sd, 
               data=data, family=binomial('logit'))
data$ps = ps.model$fitted.values %>% as.numeric()

data$ipw = 1
data$ipw[data$pg == 2] = 1/data$ps[data$pg == 2]
data$ipw[data$pg == 1] = 1/(1-data$ps[data$pg == 1])
```

The ATE estimate (and standard error) is
```{r}
data_sex = data %>% filter(i_sex==1)
ATE2 = get_weighted_tau(data_sex$i_aqoc, data_sex$pg, 
                        data_sex$ipw, normalize = TRUE)
SD2 = get_sd(data_sex$i_aqoc, data_sex$pg, 
             data_sex$ipw, normalize = TRUE)
cat(round(ATE2,4), paste0('(',round(SD2,4),')'),'\n')
```


### (c)
Within the sub-group of `sex=1`, estimate PS with all variables except `sex` and then do IPW.
```{r}
data_sex = data %>% filter(i_sex==1)
ps.model = glm(pg ~ i_age + i_race + i_educ + 
                 i_insu + i_drug + i_seve + com_t + 
                 pcs_sd + mcs_sd, 
               data=data_sex, 
               family=binomial('logit'))

data_sex$ps = ps.model$fitted.values %>% as.numeric()

data_sex$ipw = 1
data_sex$ipw[data_sex$pg == 2] = 1/data_sex$ps[data_sex$pg == 2]
data_sex$ipw[data_sex$pg == 1] = 1/(1-data_sex$ps[data_sex$pg == 1])
```

The ATE estimate (and standard error) is
```{r}
ATE3 = get_weighted_tau(data_sex$i_aqoc, data_sex$pg, 
                        data_sex$ipw, normalize = TRUE)
SD3 = get_sd(data_sex$i_aqoc, data_sex$pg, 
             data_sex$ipw, normalize = TRUE)
cat(round(ATE3,4), paste0('(',round(SD3,4),')'),'\n')
```

**(a)** and **(b)** give us very similar results, while **(c)** produces a slightly different one.

I think, among the 3 possible options, only **(c)** is correct. Note that the estimand is $\mathbb{E}(Y(1)-Y(2) \mid V=1)$, which is the difference in satisfaction probability between the two groups **within the sex=1 sub-population**. Only **(c)** is dealing with the correct target population when estimating the propensity score and doing the weighting, while the other two options are not.

## Problem 3
### 